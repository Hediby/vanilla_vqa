{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir, mkdir\n",
    "from os.path import join, exists\n",
    "from time import time\n",
    "import json\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import skimage\n",
    "from skimage.transform import resize\n",
    "from scipy.misc import imread\n",
    "from collections import Counter\n",
    "from time import time\n",
    "\n",
    "from utils import load_dataset, load_vocab,read_features, Dataset, load_emb_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VisLSTM(object):\n",
    "    def __init__(self, hyperparams):\n",
    "        self.dh = hyperparams['dh']\n",
    "        self.dq = hyperparams['dq']\n",
    "        self.da = hyperparams['da']\n",
    "        self.di = hyperparams['di']\n",
    "        self.max_q = hyperparams['max_q']\n",
    "        self.Nq = hyperparams['Nq']\n",
    "        self.Na = hyperparams['Na']\n",
    "        self.cell = hyperparams['cell']\n",
    "        self.batch_size = hyperparams['batch_size']\n",
    "        self.trainable_embeddings = hyperparams['trainable_embeddings']\n",
    "        \n",
    "        with tf.device('/cpu:0'):\n",
    "            self.qemb_W = tf.get_variable('qemb_w',\n",
    "                                          initializer=tf.random_uniform([self.Nq, self.dq], -0.1, 0.1),\n",
    "                                          trainable = self.trainable_embeddings)\n",
    "        self.aemb_W = tf.get_variable(name='aemb_w',\n",
    "                                      initializer=tf.random_uniform([self.dh, self.Na], -0.1, 0.1))\n",
    "        self.aemb_b = tf.get_variable(name='aemb_b',\n",
    "                                      initializer=tf.zeros([self.Na]))\n",
    "        self.Wi = tf.get_variable(name='Wi', shape=[self.di, self.dq],\n",
    "                                  initializer=tf.contrib.layers.xavier_initializer())\n",
    "        self.bi = tf.get_variable(name='bi',\n",
    "                                      initializer=tf.zeros([self.dq]))\n",
    "        \n",
    "        if self.cell == 'rnn':\n",
    "            self.recur = tf.nn.rnn_cell.RNNCell(self.dh)\n",
    "        elif self.cell == 'lstm':\n",
    "            self.recur = tf.nn.rnn_cell.LSTMCell(self.dh)\n",
    "        elif self.cell == 'gru':\n",
    "            self.recur = tf.nn.rnn_cell.GRUCell(self.dh)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "    def build_model(self):\n",
    "        \n",
    "        p_image = tf.placeholder(tf.float32,\n",
    "                                [None, self.di],\n",
    "                                 name=\"p_image\")\n",
    "        \n",
    "        p_keep_prob = tf.placeholder(tf.float32, name='p_keep_prob')\n",
    "        \n",
    "        p_question = tf.placeholder(tf.int32, \n",
    "                                    [None, self.max_q],\n",
    "                                    name=\"p_question\")\n",
    "        p_answer = tf.placeholder(tf.float32, \n",
    "                                  [None,self.Na],\n",
    "                                  name=\"p_answer\")\n",
    "        p_question_mask = tf.placeholder(tf.int32,\n",
    "                                         [self.max_q+1, None, None],\n",
    "                                         name=\"p_question_mask\")\n",
    "        \n",
    "        image_proj = tf.nn.xw_plus_b(p_image,self.Wi,self.bi,name='image_proj')\n",
    "        image_proj_drp = tf.nn.dropout(image_proj, p_keep_prob)\n",
    "        \n",
    "        state = self.recur.zero_state(self.batch_size, tf.float32)\n",
    "        states = []\n",
    "        outputs = []\n",
    "        for j in range(self.max_q+1):\n",
    "            if j==0:\n",
    "                output,state = self.recur(image_proj_drp, state)\n",
    "            else:\n",
    "                with tf.device('/cpu:0'):\n",
    "                    question_emb = tf.nn.embedding_lookup(self.qemb_W, p_question[:,j-1])\n",
    "                    question_emb_drp = tf.nn.dropout(question_emb, p_keep_prob)\n",
    "                tf.get_variable_scope().reuse_variables()\n",
    "                output,state = self.recur(question_emb_drp, state)\n",
    "            states.append(state)\n",
    "            outputs.append(output)\n",
    "\n",
    "        output = tf.pack(outputs) # (max_words_q, batch_size, 4*dim_hidden)\n",
    "        output_final = tf.reduce_sum(tf.mul(output, tf.to_float(p_question_mask)),0) # (batch_size, 2*dim_hidden)\n",
    "\n",
    "        answer_logits = tf.nn.xw_plus_b(output_final,\n",
    "                                        self.aemb_W,\n",
    "                                        self.aemb_b) # (batch_size, num_answer)\n",
    "        answer_pred = tf.argmax(answer_logits,1)\n",
    "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(answer_logits, p_answer) # (batch_size, )\n",
    "        loss = tf.reduce_mean(cross_entropy)\n",
    "        train_op = tf.train.AdamOptimizer().minimize(loss)\n",
    "        loss_summary = tf.scalar_summary(\"loss\",loss,name=\"loss\")\n",
    "        output = {'train_op':train_op,\n",
    "                 'loss':loss,\n",
    "                 'question':p_question,\n",
    "                 'mask':p_question_mask,\n",
    "                 'answer':p_answer,\n",
    "                  'keep_prob':p_keep_prob,\n",
    "                 'answer_pred':answer_pred,\n",
    "                 'loss_summary':loss_summary,\n",
    "                 'image':p_image}\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_feed_dict(batch,max_q,Na,batch_size):\n",
    "    V = np.zeros((batch_size, len(batch[0][0])), 'float32')\n",
    "    Q = np.zeros((batch_size, max_q), 'int32')\n",
    "    mask = np.zeros((max_q+1,batch_size), 'int32')\n",
    "    ans = np.zeros((batch_size,Na),'int32')\n",
    "    \n",
    "    for i,(im,s,a) in enumerate(batch):\n",
    "        V[i] = im\n",
    "        Q[i] = np.pad(s, (0,max_q-len(s)), 'constant')\n",
    "        mask[len(s),i] = 1\n",
    "        ans[i,a] = 1\n",
    "    mask = mask[:,:,None]\n",
    "    return V,Q,mask,ans\n",
    "\n",
    "def test(step,verbose=None):\n",
    "    acc = []\n",
    "    test_batches = test_set.batch_gen(batch_size)\n",
    "    for idx,batch in enumerate(test_batches):    \n",
    "        if verbose:\n",
    "            if idx%20==0:\n",
    "                print(\"%d - accuracy = %1.3f\"%(idx, np.mean(acc)))\n",
    "        V,Q,mask,ans = create_feed_dict(batch,max_q,Na,batch_size)\n",
    "        a_pred = sess.run(M['answer_pred'], \n",
    "                          feed_dict={M['question']:Q,\n",
    "                                     M['mask']:mask, \n",
    "                                     M['answer']:ans,\n",
    "                                     M['image']:V, \n",
    "                                     M['keep_prob']:keep_prob})\n",
    "        equals = 1*np.equal(ans.argmax(axis=1),a_pred)\n",
    "        equals = list(equals[:len(batch)])\n",
    "        acc += equals\n",
    "    acc = tf.reduce_mean(tf.to_float(acc))\n",
    "    acc_s = tf.scalar_summary(\"acc_tf\",acc,name=\"acc_tf\")\n",
    "    acc,acc_s = sess.run([acc,acc_s])\n",
    "    writer.add_summary(acc_s,step)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_rootpath = \"/home/hbenyounes/vqa/datasets/spatialgenome/\"\n",
    "train_set = Dataset(join(dataset_rootpath, 'train','images.feat'),\n",
    "                    join(dataset_rootpath, 'train','img_ids.txt'),\n",
    "                    join(dataset_rootpath, 'train','questions.idxs'),\n",
    "                    join(dataset_rootpath, 'train','answers.idxs'))\n",
    "test_set = Dataset(join(dataset_rootpath, 'test','images.feat'),\n",
    "                    join(dataset_rootpath, 'test','img_ids.txt'),\n",
    "                    join(dataset_rootpath, 'test','questions.idxs'),\n",
    "                    join(dataset_rootpath, 'test','answers.idxs'))\n",
    "\n",
    "q_i2w, q_w2i = load_vocab('datasets/spatialgenome/train/questions.vocab')\n",
    "a_i2w, a_w2i = load_vocab('datasets/spatialgenome/train/answers.vocab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(join(dataset_rootpath,'train','answers.idxs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105874, 30206)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset), len(set([' '.join(str(d)) for d in dataset]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell.LSTMCell object at 0x7fd477d2ff98>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method InteractiveSession.__del__ of <tensorflow.python.client.session.InteractiveSession object at 0x7fd55b5303c8>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\", line 171, in __del__\n",
      "    self.close()\n",
      "  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\", line 976, in close\n",
      "    self._default_session.__exit__(None, None, None)\n",
      "  File \"/usr/lib/python3.4/contextlib.py\", line 66, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py\", line 3378, in get_controller\n",
      "    % type(default))\n",
      "AssertionError: Nesting violated for default stack of <class 'weakref'> objects\n"
     ]
    }
   ],
   "source": [
    "print(\"Graph initialization\")\n",
    "model_name = \"model1\"\n",
    "root_path = \"/home/hbenyounes/vqa/results/spatialgenome/\"\n",
    "embedding_path = '/home/hbenyounes/vqa/GoogleNews.model'\n",
    "if not exists(join(root_path, model_name)):\n",
    "    mkdir(join(root_path, model_name))\n",
    "\n",
    "Nq = len(q_i2w)\n",
    "Na = len(a_i2w)\n",
    "\n",
    "max_q = train_set.max_q\n",
    "Nq = len(q_i2w)\n",
    "Na = len(a_i2w)\n",
    "\n",
    "vector_size = 200\n",
    "max_q = train_set.max_q\n",
    "H = {\"dq\":vector_size,\n",
    "     \"da\":vector_size, \n",
    "     'dh':300,\n",
    "     \"di\":4096,\n",
    "     \"Nq\":len(q_i2w),\n",
    "     \"max_q\":max_q,\n",
    "     \"Na\":len(a_i2w),\n",
    "     \"batch_size\":64,\n",
    "     \"cell\":\"lstm\",\n",
    "     \"trainable_embeddings\":True,\n",
    "     \"keep_prob\":0.5,\n",
    "     \"word2vec\":False}\n",
    "\n",
    "tf.reset_default_graph()\n",
    "model = VisLSTM(H)\n",
    "M = model.build_model()\n",
    "if H['word2vec']:\n",
    "    q_i2w, q_w2i = load_vocab(join(dataset_rootpath,'train/questions.vocab'))\n",
    "    print(\"Load word2Vec\")\n",
    "    embeddings = {}\n",
    "    for n,l in enumerate(open(embedding_path,encoding='utf-8')):\n",
    "        l = l.strip().split()\n",
    "        w = l[0]\n",
    "        vec = [float(x) for x in l[1:]]\n",
    "        embeddings[w] = vec\n",
    "    emb,c = load_emb_matrix(q_i2w, embeddings, vector_size)\n",
    "    del embeddings\n",
    "    \n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.6)\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options, \n",
    "                                                   intra_op_parallelism_threads=1))\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=100)\n",
    "writer = tf.train.SummaryWriter(join(root_path,model_name,'tf_log'), sess.graph)\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "sess.run(init)\n",
    "\n",
    "if H['word2vec']:\n",
    "    sess.run(model.qemb_W.assign(emb))\n",
    "n_parameters = sum( [np.prod(v.get_shape(),dtype='int') for v in tf.trainable_variables()])\n",
    "H['n_parameters'] = n_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - 0/715 : loss = nan - time = 0.000s\n",
      "Epoch 0 - 71/715 : loss = 5.5153 - time = 8.599s\n",
      "Epoch 0 - 142/715 : loss = 6.0173 - time = 15.734s\n",
      "Epoch 0 - 213/715 : loss = 6.9102 - time = 22.977s\n",
      "Epoch 0 - 284/715 : loss = 7.9457 - time = 30.405s\n",
      "Epoch 0 - 355/715 : loss = 8.9517 - time = 37.800s\n",
      "Epoch 0 - 426/715 : loss = 9.9843 - time = 44.910s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-9874c77f005f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m                                           \u001b[0mM\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'answer'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mans\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                                           \u001b[0mM\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m                                           M['keep_prob']:keep_prob})\n\u001b[0m\u001b[0;32m     31\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m                 \u001b[0mbreak_all\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    370\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 372\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    373\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m       results = self._do_run(handle, target_list, unique_fetches,\n\u001b[1;32m--> 636\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    637\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m       \u001b[1;31m# The movers are no longer used. Delete them.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    706\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 708\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m    709\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    713\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 715\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    716\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m    695\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m    696\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 697\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Train\n",
    "break_all = False\n",
    "batch_size = H['batch_size']\n",
    "keep_prob = H['keep_prob']\n",
    "with tf.device('/gpu:0'):\n",
    "    n_epochs = 50\n",
    "    max_test_acc = -np.Inf\n",
    "    patience = 3\n",
    "    for epoch in range(n_epochs):\n",
    "#         if epoch <2:\n",
    "#             continue\n",
    "        epoch_loss = []\n",
    "        times = 0.\n",
    "        n_batches = train_set.N // batch_size\n",
    "        train_batches = train_set.batch_gen(batch_size)\n",
    "        for idx,batch in enumerate(train_batches):\n",
    "            tic = time()\n",
    "            if idx%(n_batches//10)==0:\n",
    "                print(\"Epoch %d - %d/%d : loss = %1.4f - time = %1.3fs\"%(epoch,idx,\n",
    "                                                                         n_batches,np.mean(epoch_loss),\n",
    "                                                                         times))\n",
    "            V,Q,mask,ans = create_feed_dict(batch,max_q,Na,batch_size)\n",
    "            _,l,l_s = sess.run([M['train_op'],\n",
    "                                M['loss'],\n",
    "                                M['loss_summary']], \n",
    "                               feed_dict={M['question']:Q,\n",
    "                                          M['mask']:mask,\n",
    "                                          M['answer']:ans,\n",
    "                                          M['image']:V,\n",
    "                                          M['keep_prob']:keep_prob})\n",
    "            if np.isnan(l):\n",
    "                break_all = True\n",
    "            epoch_loss.append(l)\n",
    "            writer.add_summary(l_s,idx+epoch*n_batches)\n",
    "            times += time() - tic\n",
    "            if break_all:\n",
    "                print(\"Loss is nan at iteration %d\" % (idx+n_batches*epoch))\n",
    "                break\n",
    "        if break_all:\n",
    "            break\n",
    "        with tf.device('/cpu:0'):\n",
    "            test_acc = test((1+epoch)*n_batches)\n",
    "            print(\"Epoch %d - Test accuracy = %1.3f\" % (epoch+1, test_acc))\n",
    "        if test_acc > max_test_acc:\n",
    "            patience += 3\n",
    "            saver.save(sess, join(root_path,model_name,'model'), global_step=epoch)\n",
    "        max_test_acc = max(test_acc, max_test_acc)\n",
    "        if epoch >= patience:\n",
    "            print(\"EARLY STOPPING\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyperparams['max_test_acc'] = max_test_acc\n",
    "with open(join(root_path, model_name, 'hyperparams'),'w') as f:\n",
    "    for h in hyperparams:\n",
    "        f.write(\"%s = %s\\n\" % (h, str(hyperparams[h])))\n",
    "    f.write('\\n\\nMaximal test accuracy = %1.4f' % max_test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
