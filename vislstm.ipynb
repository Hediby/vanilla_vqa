{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os import listdir, mkdir\n",
    "from os.path import join, exists\n",
    "from time import time\n",
    "import json\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import skimage\n",
    "from skimage.transform import resize\n",
    "from scipy.misc import imread\n",
    "from collections import Counter\n",
    "from time import time\n",
    "\n",
    "from utils import load_dataset, load_vocab,read_features, Dataset, load_emb_matrix\n",
    "from vislstm import ImageQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_feed_dict(batch,max_q,Na,batch_size):\n",
    "    V = np.zeros((batch_size, len(batch[0][0])), 'float32')\n",
    "    Q = np.zeros((batch_size, max_q), 'int32')\n",
    "    mask = np.zeros((max_q+1,batch_size), 'int32')\n",
    "    ans = np.zeros((batch_size,Na),'int32')\n",
    "    \n",
    "    for i,(im,s,a) in enumerate(batch):\n",
    "        V[i] = im\n",
    "        Q[i] = np.pad(s, (0,max_q-len(s)), 'constant')\n",
    "        mask[len(s),i] = 1\n",
    "        ans[i,a] = 1\n",
    "    mask = mask[:,:,None]\n",
    "    return V,Q,mask,ans\n",
    "\n",
    "def test(step,verbose=None):\n",
    "    acc = []\n",
    "    test_batches = test_set.batch_gen(batch_size)\n",
    "    for idx,batch in enumerate(test_batches):    \n",
    "        if verbose:\n",
    "            if idx%20==0:\n",
    "                print(\"%d - accuracy = %1.3f\"%(idx, np.mean(acc)))\n",
    "        V,Q,mask,ans = create_feed_dict(batch,max_q,Na,batch_size)\n",
    "        a_pred = sess.run(model_outputs['answer_pred'], \n",
    "                          feed_dict={model_outputs['question']:Q,\n",
    "                                     model_outputs['mask']:mask, \n",
    "                                     model_outputs['answer']:ans,\n",
    "                                     model_outputs['image']:V, \n",
    "                                     model_outputs['keep_prob']:keep_prob})\n",
    "        equals = 1*np.equal(ans.argmax(axis=1),a_pred)\n",
    "        equals = list(equals[:len(batch)])\n",
    "        acc += equals\n",
    "    acc = tf.reduce_mean(tf.to_float(acc))\n",
    "    acc_s = tf.scalar_summary(\"acc_tf\",acc,name=\"acc_tf\")\n",
    "    acc,acc_s = sess.run([acc,acc_s])\n",
    "    writer.add_summary(acc_s,step)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = \"model2\"\n",
    "root_path = \"/home/hbenyounes/vqa/word2vec_finetuned/\"\n",
    "embedding_path = '/home/hbenyounes/vqa/GoogleNews.model'\n",
    "vector_size = 300\n",
    "hyperparams = {\"dh\":2048, \n",
    "               \"dq\":vector_size,\n",
    "               \"da\":200, \n",
    "               \"di\":4096,\n",
    "               \"batch_size\":32,\n",
    "               \"keep_prob\":0.5,\n",
    "               \"cell\":\"lstm\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load word2Vec\n"
     ]
    }
   ],
   "source": [
    "q_i2w, q_w2i = load_vocab('datasets/coco/train/questions.vocab')\n",
    "\n",
    "print(\"Load word2Vec\")\n",
    "embeddings = {}\n",
    "for n,l in enumerate(open(embedding_path,encoding='utf-8')):\n",
    "    l = l.strip().split()\n",
    "    w = l[0]\n",
    "    vec = [float(x) for x in l[1:]]\n",
    "    embeddings[w] = vec\n",
    "\n",
    "emb,c = load_emb_matrix(q_i2w, embeddings)\n",
    "del embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse features file\n",
      "Parse questions file\n",
      "Parse answers file\n",
      "Parse features file\n",
      "Parse questions file\n",
      "Parse answers file\n"
     ]
    }
   ],
   "source": [
    "train_set = Dataset(\"/home/hbenyounes/vqa/datasets/coco/train/images.feat\",\n",
    "                    \"/home/hbenyounes/vqa/datasets/coco/train/img_ids.txt\",\n",
    "                    \"/home/hbenyounes/vqa/datasets/coco/train/questions.idxs\",\n",
    "                    \"/home/hbenyounes/vqa/datasets/coco/train/answers.idxs\")\n",
    "\n",
    "\n",
    "test_set = Dataset(\"/home/hbenyounes/vqa/datasets/coco/test/images.feat\",\n",
    "                    \"/home/hbenyounes/vqa/datasets/coco/test/img_ids.txt\",\n",
    "                    \"/home/hbenyounes/vqa/datasets/coco/test/questions.idxs\",\n",
    "                    \"/home/hbenyounes/vqa/datasets/coco/test/answers.idxs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell.LSTMCell object at 0x7f614b408f60>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method InteractiveSession.__del__ of <tensorflow.python.client.session.InteractiveSession object at 0x7f63a6be1048>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\", line 171, in __del__\n",
      "    self.close()\n",
      "  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\", line 976, in close\n",
      "    self._default_session.__exit__(None, None, None)\n",
      "  File \"/usr/lib/python3.4/contextlib.py\", line 66, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py\", line 3378, in get_controller\n",
      "    % type(default))\n",
      "AssertionError: Nesting violated for default stack of <class 'weakref'> objects\n"
     ]
    }
   ],
   "source": [
    "if not exists(join(root_path, model_name)):\n",
    "    mkdir(join(root_path, model_name))\n",
    "\n",
    "q_i2w, q_w2i = load_vocab('datasets/coco/train/questions.vocab')\n",
    "a_i2w, a_w2i = load_vocab('datasets/coco/train/answers.vocab')\n",
    "Nq = len(q_i2w)\n",
    "Na = len(a_i2w)\n",
    "\n",
    "max_q = train_set.max_q\n",
    "Nq = len(q_i2w)\n",
    "Na = len(a_i2w)\n",
    "\n",
    "\n",
    "dh = hyperparams[\"dh\"] #GRU hidden state dimension\n",
    "dq = hyperparams[\"dq\"] #Question embedding dimension\n",
    "da = hyperparams[\"da\"] #Answer embedding dimension\n",
    "di = hyperparams[\"di\"] #Image dimension\n",
    "batch_size = hyperparams[\"batch_size\"]\n",
    "keep_prob = hyperparams[\"keep_prob\"]\n",
    "cell = hyperparams[\"cell\"]\n",
    "\n",
    "print(\"Graph initialization\")\n",
    "tf.reset_default_graph()\n",
    "model = ImageQA(dh,dq,da,di,max_q,Nq,Na,cell,True)\n",
    "model_outputs = model.build_model(batch_size)\n",
    "\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.6)\n",
    "\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options, \n",
    "                                                   intra_op_parallelism_threads=4))\n",
    "\n",
    "writer = tf.train.SummaryWriter(join(root_path,model_name,'tf_log'), sess.graph)\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=100)\n",
    "\n",
    "\n",
    "# saver.restore(sess, '/home/hbenyounes/vqa/word2vec_fixed/model3/model-1')\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "sess.run(init)\n",
    "\n",
    "\n",
    "sess.run(model.qemb_W.assign(emb))\n",
    "\n",
    "n_parameters = sum( [np.prod(v.get_shape(),dtype='int') for v in tf.trainable_variables()])\n",
    "hyperparams['n_parameters'] = n_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - 0/2460 : loss = nan - time = 0.000s\n",
      "Epoch 0 - 246/2460 : loss = 3.9261 - time = 50.023s\n",
      "Epoch 0 - 492/2460 : loss = 3.4992 - time = 100.434s\n",
      "Epoch 0 - 738/2460 : loss = 3.2678 - time = 151.008s\n",
      "Epoch 0 - 984/2460 : loss = 3.1050 - time = 201.725s\n",
      "Epoch 0 - 1230/2460 : loss = 2.9768 - time = 252.700s\n",
      "Epoch 0 - 1476/2460 : loss = 2.8701 - time = 303.806s\n",
      "Epoch 0 - 1722/2460 : loss = 2.7951 - time = 356.559s\n",
      "Epoch 0 - 1968/2460 : loss = 2.7212 - time = 408.152s\n",
      "Epoch 0 - 2214/2460 : loss = 2.6633 - time = 460.397s\n",
      "Epoch 1 - Test accuracy = 0.449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method InteractiveSession.__del__ of <tensorflow.python.client.session.InteractiveSession object at 0x7f6207753e48>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\", line 171, in __del__\n",
      "    self.close()\n",
      "  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\", line 976, in close\n",
      "    self._default_session.__exit__(None, None, None)\n",
      "  File \"/usr/lib/python3.4/contextlib.py\", line 66, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py\", line 3378, in get_controller\n",
      "    % type(default))\n",
      "AssertionError: Nesting violated for default stack of <class 'weakref'> objects\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - 0/2460 : loss = nan - time = 0.000s\n",
      "Epoch 1 - 246/2460 : loss = 1.9921 - time = 52.311s\n",
      "Epoch 1 - 492/2460 : loss = 1.9830 - time = 105.464s\n",
      "Epoch 1 - 738/2460 : loss = 1.9846 - time = 158.098s\n",
      "Epoch 1 - 984/2460 : loss = 1.9769 - time = 218.559s\n",
      "Epoch 1 - 1230/2460 : loss = 1.9615 - time = 273.159s\n",
      "Epoch 1 - 1476/2460 : loss = 1.9536 - time = 329.130s\n",
      "Epoch 1 - 1722/2460 : loss = 1.9473 - time = 399.091s\n",
      "Epoch 1 - 1968/2460 : loss = 1.9366 - time = 462.506s\n",
      "Epoch 1 - 2214/2460 : loss = 1.9326 - time = 517.179s\n",
      "Epoch 2 - Test accuracy = 0.491\n",
      "Epoch 2 - 0/2460 : loss = nan - time = 0.000s\n",
      "Epoch 2 - 246/2460 : loss = 1.6562 - time = 58.450s\n",
      "Epoch 2 - 492/2460 : loss = 1.6576 - time = 110.857s\n",
      "Epoch 2 - 738/2460 : loss = 1.6661 - time = 163.290s\n",
      "Epoch 2 - 984/2460 : loss = 1.6722 - time = 224.471s\n",
      "Epoch 2 - 1230/2460 : loss = 1.6765 - time = 294.955s\n",
      "Epoch 2 - 1476/2460 : loss = 1.6732 - time = 365.042s\n",
      "Epoch 2 - 1722/2460 : loss = 1.6739 - time = 435.210s\n",
      "Epoch 2 - 1968/2460 : loss = 1.6740 - time = 505.048s\n",
      "Epoch 2 - 2214/2460 : loss = 1.6722 - time = 574.813s\n",
      "Epoch 3 - Test accuracy = 0.507\n",
      "Epoch 3 - 0/2460 : loss = nan - time = 0.000s\n",
      "Epoch 3 - 246/2460 : loss = 1.4509 - time = 69.616s\n",
      "Epoch 3 - 492/2460 : loss = 1.4733 - time = 138.542s\n",
      "Epoch 3 - 738/2460 : loss = 1.4721 - time = 190.918s\n",
      "Epoch 3 - 984/2460 : loss = 1.4718 - time = 243.704s\n",
      "Epoch 3 - 1230/2460 : loss = 1.4676 - time = 296.681s\n",
      "Epoch 3 - 1476/2460 : loss = 1.4713 - time = 349.355s\n",
      "Epoch 3 - 1722/2460 : loss = 1.4795 - time = 402.177s\n",
      "Epoch 3 - 1968/2460 : loss = 1.4818 - time = 454.960s\n",
      "Epoch 3 - 2214/2460 : loss = 1.4859 - time = 507.759s\n",
      "Epoch 4 - Test accuracy = 0.516\n",
      "Epoch 4 - 0/2460 : loss = nan - time = 0.000s\n",
      "Epoch 4 - 246/2460 : loss = 1.2591 - time = 52.585s\n",
      "Epoch 4 - 492/2460 : loss = 1.2495 - time = 106.023s\n",
      "Epoch 4 - 738/2460 : loss = 1.2812 - time = 159.217s\n",
      "Epoch 4 - 984/2460 : loss = 1.2889 - time = 214.189s\n",
      "Epoch 4 - 1230/2460 : loss = 1.2970 - time = 269.502s\n",
      "Epoch 4 - 1476/2460 : loss = 1.3012 - time = 322.207s\n",
      "Epoch 4 - 1722/2460 : loss = 1.3053 - time = 377.360s\n",
      "Epoch 4 - 1968/2460 : loss = 1.3061 - time = 443.058s\n",
      "Epoch 4 - 2214/2460 : loss = 1.3090 - time = 515.681s\n",
      "Epoch 5 - Test accuracy = 0.515\n",
      "Epoch 5 - 0/2460 : loss = nan - time = 0.000s\n",
      "Epoch 5 - 246/2460 : loss = 1.0787 - time = 71.407s\n",
      "Epoch 5 - 492/2460 : loss = 1.0744 - time = 142.974s\n",
      "Epoch 5 - 738/2460 : loss = 1.0898 - time = 215.261s\n",
      "Epoch 5 - 984/2460 : loss = 1.1002 - time = 286.860s\n",
      "Epoch 5 - 1230/2460 : loss = 1.1110 - time = 358.735s\n",
      "Epoch 5 - 1476/2460 : loss = 1.1249 - time = 430.416s\n",
      "Epoch 5 - 1722/2460 : loss = 1.1343 - time = 502.099s\n",
      "Epoch 5 - 1968/2460 : loss = 1.1426 - time = 574.083s\n",
      "Epoch 5 - 2214/2460 : loss = 1.1489 - time = 645.755s\n",
      "Epoch 6 - Test accuracy = 0.507\n",
      "Epoch 6 - 0/2460 : loss = nan - time = 0.000s\n",
      "Epoch 6 - 246/2460 : loss = 0.9133 - time = 71.422s\n",
      "Epoch 6 - 492/2460 : loss = 0.9386 - time = 142.472s\n",
      "Epoch 6 - 738/2460 : loss = 0.9637 - time = 213.820s\n",
      "Epoch 6 - 984/2460 : loss = 0.9730 - time = 285.129s\n",
      "Epoch 6 - 1230/2460 : loss = 0.9793 - time = 356.717s\n",
      "Epoch 6 - 1476/2460 : loss = 0.9906 - time = 428.082s\n",
      "Epoch 6 - 1722/2460 : loss = 0.9973 - time = 499.566s\n",
      "Epoch 6 - 1968/2460 : loss = 1.0001 - time = 571.503s\n",
      "Epoch 6 - 2214/2460 : loss = 1.0062 - time = 643.205s\n",
      "Epoch 7 - Test accuracy = 0.509\n",
      "Epoch 7 - 0/2460 : loss = nan - time = 0.000s\n",
      "Epoch 7 - 246/2460 : loss = 0.7936 - time = 71.466s\n",
      "Epoch 7 - 492/2460 : loss = 0.8094 - time = 143.084s\n",
      "Epoch 7 - 738/2460 : loss = 0.8163 - time = 214.513s\n",
      "Epoch 7 - 984/2460 : loss = 0.8303 - time = 285.805s\n",
      "Epoch 7 - 1230/2460 : loss = 0.8430 - time = 357.143s\n",
      "Epoch 7 - 1476/2460 : loss = 0.8533 - time = 428.859s\n",
      "Epoch 7 - 1722/2460 : loss = 0.8653 - time = 500.448s\n",
      "Epoch 7 - 1968/2460 : loss = 0.8777 - time = 572.352s\n",
      "Epoch 7 - 2214/2460 : loss = 0.8891 - time = 644.555s\n",
      "Epoch 8 - Test accuracy = 0.498\n",
      "Epoch 8 - 0/2460 : loss = nan - time = 0.000s\n",
      "Epoch 8 - 246/2460 : loss = 0.7137 - time = 72.298s\n",
      "Epoch 8 - 492/2460 : loss = 0.7377 - time = 143.599s\n",
      "Epoch 8 - 738/2460 : loss = 0.7414 - time = 215.676s\n",
      "Epoch 8 - 984/2460 : loss = 0.7489 - time = 287.358s\n",
      "Epoch 8 - 1230/2460 : loss = 0.7539 - time = 358.342s\n",
      "Epoch 8 - 1476/2460 : loss = 0.7646 - time = 429.904s\n",
      "Epoch 8 - 1722/2460 : loss = 0.7688 - time = 501.124s\n",
      "Epoch 8 - 1968/2460 : loss = 0.7780 - time = 572.817s\n",
      "Epoch 8 - 2214/2460 : loss = 0.7856 - time = 644.826s\n",
      "Epoch 9 - Test accuracy = 0.501\n",
      "Epoch 9 - 0/2460 : loss = nan - time = 0.000s\n",
      "Epoch 9 - 246/2460 : loss = 0.6169 - time = 54.439s\n",
      "Epoch 9 - 492/2460 : loss = 0.6345 - time = 107.114s\n",
      "Epoch 9 - 738/2460 : loss = 0.6460 - time = 159.896s\n",
      "Epoch 9 - 984/2460 : loss = 0.6557 - time = 212.925s\n",
      "Epoch 9 - 1230/2460 : loss = 0.6680 - time = 265.803s\n",
      "Epoch 9 - 1476/2460 : loss = 0.6806 - time = 318.773s\n",
      "Epoch 9 - 1722/2460 : loss = 0.6940 - time = 371.765s\n",
      "Epoch 9 - 1968/2460 : loss = 0.7026 - time = 424.964s\n",
      "Epoch 9 - 2214/2460 : loss = 0.7141 - time = 477.695s\n",
      "Epoch 10 - Test accuracy = 0.493\n",
      "Epoch 10 - 0/2460 : loss = nan - time = 0.000s\n",
      "Epoch 10 - 246/2460 : loss = 0.5868 - time = 53.270s\n",
      "Epoch 10 - 492/2460 : loss = 0.5986 - time = 106.084s\n",
      "Epoch 10 - 738/2460 : loss = 0.6126 - time = 159.683s\n",
      "Epoch 10 - 984/2460 : loss = 0.6254 - time = 213.439s\n",
      "Epoch 10 - 1230/2460 : loss = 0.6341 - time = 266.778s\n",
      "Epoch 10 - 1476/2460 : loss = 0.6445 - time = 320.119s\n",
      "Epoch 10 - 1722/2460 : loss = 0.6556 - time = 373.778s\n",
      "Epoch 10 - 1968/2460 : loss = 0.6615 - time = 427.222s\n",
      "Epoch 10 - 2214/2460 : loss = 0.6717 - time = 481.305s\n",
      "Epoch 11 - Test accuracy = 0.491\n",
      "Epoch 11 - 0/2460 : loss = nan - time = 0.000s\n",
      "Epoch 11 - 246/2460 : loss = 0.5402 - time = 53.024s\n",
      "Epoch 11 - 492/2460 : loss = 0.5513 - time = 106.304s\n",
      "Epoch 11 - 738/2460 : loss = 0.5654 - time = 160.013s\n",
      "Epoch 11 - 984/2460 : loss = 0.5740 - time = 213.863s\n",
      "Epoch 11 - 1230/2460 : loss = 0.5855 - time = 267.289s\n",
      "Epoch 11 - 1476/2460 : loss = 0.5942 - time = 320.656s\n",
      "Epoch 11 - 1722/2460 : loss = 0.6054 - time = 374.955s\n",
      "Epoch 11 - 1968/2460 : loss = 0.6179 - time = 428.708s\n",
      "Epoch 11 - 2214/2460 : loss = 0.6258 - time = 483.882s\n",
      "Epoch 12 - Test accuracy = 0.487\n",
      "Epoch 12 - 0/2460 : loss = nan - time = 0.000s\n",
      "Epoch 12 - 246/2460 : loss = 0.5264 - time = 52.800s\n",
      "Epoch 12 - 492/2460 : loss = 0.5381 - time = 105.749s\n",
      "Epoch 12 - 738/2460 : loss = 0.5504 - time = 158.577s\n",
      "Epoch 12 - 984/2460 : loss = 0.5562 - time = 211.530s\n",
      "Epoch 12 - 1230/2460 : loss = 0.5630 - time = 264.370s\n",
      "Epoch 12 - 1476/2460 : loss = 0.5722 - time = 317.260s\n",
      "Epoch 12 - 1722/2460 : loss = 0.5839 - time = 370.150s\n",
      "Epoch 12 - 1968/2460 : loss = 0.5921 - time = 423.083s\n",
      "Epoch 12 - 2214/2460 : loss = 0.6013 - time = 476.634s\n",
      "Epoch 13 - Test accuracy = 0.481\n",
      "Epoch 13 - 0/2460 : loss = nan - time = 0.000s\n",
      "Epoch 13 - 246/2460 : loss = 0.5089 - time = 53.383s\n",
      "Epoch 13 - 492/2460 : loss = 0.5219 - time = 106.170s\n",
      "Epoch 13 - 738/2460 : loss = 0.5362 - time = 158.858s\n",
      "Epoch 13 - 984/2460 : loss = 0.5537 - time = 212.728s\n",
      "Epoch 13 - 1230/2460 : loss = 0.5621 - time = 266.594s\n",
      "Epoch 13 - 1476/2460 : loss = 0.5699 - time = 320.972s\n",
      "Epoch 13 - 1722/2460 : loss = 0.5767 - time = 376.723s\n",
      "Epoch 13 - 1968/2460 : loss = 0.5862 - time = 432.373s\n",
      "Epoch 13 - 2214/2460 : loss = 0.5943 - time = 486.393s\n",
      "Epoch 14 - Test accuracy = 0.478\n",
      "Epoch 14 - 0/2460 : loss = nan - time = 0.000s\n",
      "Epoch 14 - 246/2460 : loss = 0.5380 - time = 54.862s\n",
      "Epoch 14 - 492/2460 : loss = 0.5431 - time = 108.280s\n",
      "Epoch 14 - 738/2460 : loss = 0.5476 - time = 161.483s\n",
      "Epoch 14 - 984/2460 : loss = 0.5550 - time = 214.455s\n",
      "Epoch 14 - 1230/2460 : loss = 0.5639 - time = 268.014s\n",
      "Epoch 14 - 1476/2460 : loss = 0.5700 - time = 321.053s\n",
      "Epoch 14 - 1722/2460 : loss = 0.5790 - time = 374.026s\n",
      "Epoch 14 - 1968/2460 : loss = 0.5836 - time = 427.004s\n",
      "Epoch 14 - 2214/2460 : loss = 0.5915 - time = 480.015s\n",
      "Epoch 15 - Test accuracy = 0.484\n",
      "Epoch 15 - 0/2460 : loss = nan - time = 0.000s\n",
      "Epoch 15 - 246/2460 : loss = 0.5169 - time = 52.967s\n",
      "Epoch 15 - 492/2460 : loss = 0.5242 - time = 105.909s\n",
      "Epoch 15 - 738/2460 : loss = 0.5295 - time = 159.441s\n",
      "Epoch 15 - 984/2460 : loss = 0.5346 - time = 212.550s\n",
      "Epoch 15 - 1230/2460 : loss = 0.5387 - time = 265.535s\n",
      "Epoch 15 - 1476/2460 : loss = 0.5468 - time = 318.572s\n",
      "Epoch 15 - 1722/2460 : loss = 0.5481 - time = 371.685s\n",
      "Epoch 15 - 1968/2460 : loss = 0.5558 - time = 424.881s\n",
      "Epoch 15 - 2214/2460 : loss = 0.5617 - time = 478.244s\n",
      "Epoch 16 - Test accuracy = 0.482\n",
      "EARLY STOPPING\n"
     ]
    }
   ],
   "source": [
    "#Train\n",
    "break_all = False\n",
    "with tf.device('/gpu:0'):\n",
    "    n_epochs = 50\n",
    "    max_test_acc = -np.Inf\n",
    "    patience = 3\n",
    "    for epoch in range(n_epochs):\n",
    "#         if epoch <2:\n",
    "#             continue\n",
    "        epoch_loss = []\n",
    "        times = 0.\n",
    "        n_batches = train_set.N // batch_size\n",
    "        train_batches = train_set.batch_gen(batch_size)\n",
    "        for idx,batch in enumerate(train_batches):\n",
    "            tic = time()\n",
    "            if idx%(n_batches//10)==0:\n",
    "                print(\"Epoch %d - %d/%d : loss = %1.4f - time = %1.3fs\"%(epoch,idx,\n",
    "                                                                         n_batches,np.mean(epoch_loss),\n",
    "                                                                         times))\n",
    "            V,Q,mask,ans = create_feed_dict(batch,max_q,Na,batch_size)\n",
    "            _,l,l_s = sess.run([model_outputs['train_op'],\n",
    "                                model_outputs['loss'],\n",
    "                                model_outputs['loss_summary']], \n",
    "                               feed_dict={model_outputs['question']:Q,\n",
    "                                          model_outputs['mask']:mask,\n",
    "                                          model_outputs['answer']:ans,\n",
    "                                          model_outputs['image']:V,\n",
    "                                          model_outputs['keep_prob']:keep_prob})\n",
    "            if np.isnan(l):\n",
    "                break_all = True\n",
    "            epoch_loss.append(l)\n",
    "            writer.add_summary(l_s,idx+epoch*n_batches)\n",
    "            times += time() - tic\n",
    "            if break_all:\n",
    "                print(\"Loss is nan at iteration %d\" % (idx+n_batches*epoch))\n",
    "                break\n",
    "        if break_all:\n",
    "            break\n",
    "        with tf.device('/cpu:0'):\n",
    "            test_acc = test((1+epoch)*n_batches)\n",
    "            print(\"Epoch %d - Test accuracy = %1.3f\" % (epoch+1, test_acc))\n",
    "        if test_acc > max_test_acc:\n",
    "            patience += 3\n",
    "            saver.save(sess, join(root_path,model_name,'model'), global_step=epoch)\n",
    "        max_test_acc = max(test_acc, max_test_acc)\n",
    "        if epoch >= patience:\n",
    "            print(\"EARLY STOPPING\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyperparams['max_test_acc'] = max_test_acc\n",
    "with open(join(root_path, model_name, 'hyperparams'),'w') as f:\n",
    "    for h in hyperparams:\n",
    "        f.write(\"%s = %s\\n\" % (h, str(hyperparams[h])))\n",
    "    f.write('\\n\\nMaximal test accuracy = %1.4f' % max_test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
