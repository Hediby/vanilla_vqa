{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os import listdir, mkdir\n",
    "from os.path import join, exists\n",
    "from time import time\n",
    "import json\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import skimage\n",
    "from skimage.transform import resize\n",
    "from scipy.misc import imread\n",
    "from collections import Counter\n",
    "from time import time\n",
    "\n",
    "from utils import load_dataset, load_vocab,read_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, f_path, i_path, q_path, a_path, n_max=np.Inf):\n",
    "        self.f_path = f_path\n",
    "        self.i_path = i_path\n",
    "        self.q_path = q_path\n",
    "        self.a_path = a_path\n",
    "        print('Parse features file')\n",
    "        self.images_lines = {}\n",
    "        self.images_features = []\n",
    "        for i,l in enumerate(open(self.f_path)):\n",
    "            l = l.split(';')\n",
    "            self.images_lines[l[0]] = i\n",
    "            self.images_features.append([float(x) for x in l[1].split()])\n",
    "        print('Parse questions file')\n",
    "        \n",
    "        q_data = load_dataset(self.q_path)\n",
    "        self.max_q = len(max(q_data, key=lambda x:len(x)))\n",
    "        print('Parse answers file')\n",
    "        a_data = load_dataset(self.a_path)\n",
    "        self.data = []\n",
    "        for q_id,q,a in zip(open(i_path),q_data,a_data):\n",
    "            q_id = q_id.strip()\n",
    "            try:\n",
    "                l_num = self.images_lines[q_id]\n",
    "            except:\n",
    "                continue\n",
    "            datum = (l_num,q,a)\n",
    "            self.data.append(datum)\n",
    "        self.data = np.array(self.data, dtype=object)\n",
    "        del q_data,a_data\n",
    "        self.N = len(self.data)\n",
    "        self.indexes = np.arange(self.N)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def batch_gen(self,batch_size=64):\n",
    "        np.random.shuffle(self.indexes)\n",
    "        n_batches = self.N // batch_size\n",
    "        for batch_id in range(n_batches):\n",
    "            begin = batch_id*batch_size\n",
    "            end = min((batch_id+1)*batch_size, self.N)\n",
    "            B = self.data[self.indexes[begin:end]]\n",
    "            B = [(self.images_features[b[0]],b[1],b[2]) for b in B]\n",
    "#                 all_image_indexes = [b[0] for b in B]\n",
    "#                 saved_order = dict((idx,order) for order,idx in enumerate(all_image_indexes))\n",
    "#                 S = sorted(saved_order,reverse=True)\n",
    "#                 current_line = S.pop()\n",
    "#                 for i,l in enumerate(f):\n",
    "#                     if i == current_line:\n",
    "#                         l = l.split(';')\n",
    "#                         vec = [float(x) for x in l[1].split()]\n",
    "#                         B[saved_order[current_line]][0] = vec\n",
    "#                         current_line = S.pop()\n",
    "#                         if len(S) == 0:\n",
    "#                             break\n",
    "            yield B\n",
    "        \n",
    "#         batch = []\n",
    "#         np.random.shuffle(self.indexes)\n",
    "#         with open(self.f_path) as f:\n",
    "#             for idx in self.indexes:\n",
    "#                 datum = self.data[self.indexes[idx]]\n",
    "#                 query = datum[0]\n",
    "#                 vec = []\n",
    "#                 print(query)\n",
    "#                 for i,l in enumerate(f):\n",
    "#                     if i==query:\n",
    "#                         l = l.split(';')\n",
    "#                         vec = [float(x) for x in l[1].split()]\n",
    "#                         break\n",
    "#                 batch.append((vec,datum[1],datum[2]))\n",
    "#                 if len(batch) == batch_size:\n",
    "#                     yield batch\n",
    "#                     batch = []\n",
    "#             if len(batch)>0:\n",
    "#                 yield batch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_emb_matrix(q_i2w, embeddings):\n",
    "    out = []\n",
    "    c = set()\n",
    "    for w in q_i2w:\n",
    "        if w in embeddings:\n",
    "            out.append(embeddings[w])\n",
    "        else:\n",
    "            c.add(w)\n",
    "            out.append(np.zeros((vector_size,)))\n",
    "    return (np.array(out),c)\n",
    "\n",
    "def create_feed_dict(batch,max_q,Na,batch_size):\n",
    "    V = np.zeros((batch_size, len(batch[0][0])), 'float32')\n",
    "    Q = np.zeros((batch_size, max_q), 'int32')\n",
    "    mask = np.zeros((max_q+1,batch_size), 'int32')\n",
    "    ans = np.zeros((batch_size,Na),'int32')\n",
    "    \n",
    "    for i,(im,s,a) in enumerate(batch):\n",
    "        V[i] = im\n",
    "        Q[i] = np.pad(s, (0,max_q-len(s)), 'constant')\n",
    "        mask[len(s),i] = 1\n",
    "        ans[i,a] = 1\n",
    "    mask = mask[:,:,None]\n",
    "    return V,Q,mask,ans\n",
    "\n",
    "def test(step,verbose=None):\n",
    "    acc = []\n",
    "    test_batches = test_set.batch_gen(batch_size)\n",
    "    for idx,batch in enumerate(test_batches):    \n",
    "        if verbose:\n",
    "            if idx%20==0:\n",
    "                print(\"%d - accuracy = %1.3f\"%(idx, np.mean(acc)))\n",
    "        V,Q,mask,ans = create_feed_dict(batch,max_q,Na,batch_size)\n",
    "        a_pred = sess.run(model_outputs['answer_pred'], \n",
    "                          feed_dict={model_outputs['question']:Q,\n",
    "                                     model_outputs['mask']:mask, \n",
    "                                     model_outputs['answer']:ans,\n",
    "                                     model_outputs['image']:V, \n",
    "                                     model_outputs['keep_prob']:keep_prob})\n",
    "        equals = 1*np.equal(ans.argmax(axis=1),a_pred)\n",
    "        equals = list(equals[:len(batch)])\n",
    "        acc += equals\n",
    "    acc = tf.reduce_mean(tf.to_float(acc))\n",
    "    acc_s = tf.scalar_summary(\"acc_tf\",acc,name=\"acc_tf\")\n",
    "    acc,acc_s = sess.run([acc,acc_s])\n",
    "    writer.add_summary(acc_s,step)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = \"model3\"\n",
    "root_path = \"/home/hbenyounes/vqa/word2vec_fixed/\"\n",
    "embedding_path = '/home/hbenyounes/vqa/GoogleNews.model'\n",
    "vector_size = 300\n",
    "hyperparams = {\"dh\":2048, \n",
    "               \"dq\":vector_size,\n",
    "               \"da\":200, \n",
    "               \"di\":4096,\n",
    "               \"batch_size\":32,\n",
    "               \"keep_prob\":0.8,\n",
    "               \"cell\":\"lstm\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load word2Vec\n"
     ]
    }
   ],
   "source": [
    "q_i2w, q_w2i = load_vocab('datasets/coco/train/questions.vocab')\n",
    "\n",
    "print(\"Load word2Vec\")\n",
    "embeddings = {}\n",
    "for n,l in enumerate(open(embedding_path,encoding='utf-8')):\n",
    "    l = l.strip().split()\n",
    "    w = l[0]\n",
    "    vec = [float(x) for x in l[1:]]\n",
    "    embeddings[w] = vec\n",
    "\n",
    "emb,c = load_emb_matrix(q_i2w, embeddings)\n",
    "del embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse features file\n",
      "Parse questions file\n",
      "Parse answers file\n",
      "Parse features file\n",
      "Parse questions file\n",
      "Parse answers file\n"
     ]
    }
   ],
   "source": [
    "train_set = Dataset(\"/home/hbenyounes/vqa/datasets/coco/train/images.feat\",\n",
    "                    \"/home/hbenyounes/vqa/datasets/coco/train/img_ids.txt\",\n",
    "                    \"/home/hbenyounes/vqa/datasets/coco/train/questions.idxs\",\n",
    "                    \"/home/hbenyounes/vqa/datasets/coco/train/answers.idxs\")\n",
    "\n",
    "\n",
    "test_set = Dataset(\"/home/hbenyounes/vqa/datasets/coco/test/images.feat\",\n",
    "                    \"/home/hbenyounes/vqa/datasets/coco/test/img_ids.txt\",\n",
    "                    \"/home/hbenyounes/vqa/datasets/coco/test/questions.idxs\",\n",
    "                    \"/home/hbenyounes/vqa/datasets/coco/test/answers.idxs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ImageQA(object):\n",
    "    def __init__(self, dh, dq, da, di, max_q, Nq, Na, cell='rnn',trainable_embeddings=True):\n",
    "        self.dh = dh\n",
    "        self.dq = dq\n",
    "        self.da = da\n",
    "        self.di = di\n",
    "        self.max_q = max_q\n",
    "        self.Nq = Nq\n",
    "        self.Na = Na\n",
    "        self.cell = cell\n",
    "        \n",
    "        with tf.device('/cpu:0'):\n",
    "            self.qemb_W = tf.get_variable('qemb_w',\n",
    "                                          initializer=tf.random_uniform([self.Nq, self.dq], -0.1, 0.1),\n",
    "                                          trainable = trainable_embeddings)\n",
    "        self.aemb_W = tf.get_variable(name='aemb_w',\n",
    "                                      initializer=tf.random_uniform([self.dh, self.Na], -0.1, 0.1))\n",
    "        self.aemb_b = tf.get_variable(name='aemb_b',\n",
    "                                      initializer=tf.zeros([self.Na]))\n",
    "        self.Wi = tf.get_variable(name='Wi', shape=[self.di, self.dq],\n",
    "                                  initializer=tf.contrib.layers.xavier_initializer())\n",
    "        self.bi = tf.get_variable(name='bi',\n",
    "                                      initializer=tf.zeros([self.dq]))\n",
    "        \n",
    "        if self.cell == 'rnn':\n",
    "            self.recur = tf.nn.rnn_cell.RNNCell(self.dh)\n",
    "        elif self.cell == 'lstm':\n",
    "            self.recur = tf.nn.rnn_cell.LSTMCell(self.dh)\n",
    "        elif self.cell == 'gru':\n",
    "            self.recur = tf.nn.rnn_cell.GRUCell(self.dh)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "    def build_model(self,batch_size):\n",
    "        \n",
    "        p_image = tf.placeholder(tf.float32,\n",
    "                                [None, self.di],\n",
    "                                 name=\"p_image\")\n",
    "        \n",
    "        p_keep_prob = tf.placeholder(tf.float32, name='p_keep_prob')\n",
    "        \n",
    "        p_question = tf.placeholder(tf.int32, \n",
    "                                    [None, self.max_q],\n",
    "                                    name=\"p_question\")\n",
    "        p_answer = tf.placeholder(tf.float32, \n",
    "                                  [None,self.Na],\n",
    "                                  name=\"p_answer\")\n",
    "        p_question_mask = tf.placeholder(tf.int32,\n",
    "                                         [self.max_q+1, None, None],\n",
    "                                         name=\"p_question_mask\")\n",
    "        \n",
    "        image_proj = tf.nn.xw_plus_b(p_image,self.Wi,self.bi,name='image_proj')\n",
    "        image_proj_drp = tf.nn.dropout(image_proj, p_keep_prob)\n",
    "        \n",
    "        state = self.recur.zero_state(batch_size, tf.float32)\n",
    "        states = []\n",
    "        outputs = []\n",
    "        for j in range(self.max_q+1):\n",
    "            if j==0:\n",
    "                output,state = self.recur(image_proj_drp, state)\n",
    "            else:\n",
    "                with tf.device('/cpu:0'):\n",
    "                    question_emb = tf.nn.embedding_lookup(self.qemb_W, p_question[:,j-1])\n",
    "                    question_emb_drp = tf.nn.dropout(question_emb, p_keep_prob)\n",
    "                tf.get_variable_scope().reuse_variables()\n",
    "                output,state = self.recur(question_emb_drp, state)\n",
    "            states.append(state)\n",
    "            outputs.append(output)\n",
    "\n",
    "        output = tf.pack(outputs) # (max_words_q, batch_size, 4*dim_hidden)\n",
    "        output_final = tf.reduce_sum(tf.mul(output, tf.to_float(p_question_mask)),0) # (batch_size, 2*dim_hidden)\n",
    "\n",
    "        answer_logits = tf.nn.xw_plus_b(output_final,\n",
    "                                        self.aemb_W,\n",
    "                                        self.aemb_b) # (batch_size, num_answer)\n",
    "        answer_pred = tf.argmax(answer_logits,1)\n",
    "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(answer_logits, p_answer) # (batch_size, )\n",
    "        loss = tf.reduce_mean(cross_entropy)\n",
    "        train_op = tf.train.AdamOptimizer().minimize(loss)\n",
    "        loss_summary = tf.scalar_summary(\"loss\",loss,name=\"loss\")\n",
    "        output = {'train_op':train_op,\n",
    "                 'loss':loss,\n",
    "                 'question':p_question,\n",
    "                 'mask':p_question_mask,\n",
    "                 'answer':p_answer,\n",
    "                  'keep_prob':p_keep_prob,\n",
    "                 'answer_pred':answer_pred,\n",
    "                 'loss_summary':loss_summary,\n",
    "                 'image':p_image}\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell.LSTMCell object at 0x7f195cf468d0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph initialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method InteractiveSession.__del__ of <tensorflow.python.client.session.InteractiveSession object at 0x7f17bca69f60>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\", line 171, in __del__\n",
      "    self.close()\n",
      "  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\", line 976, in close\n",
      "    self._default_session.__exit__(None, None, None)\n",
      "  File \"/usr/lib/python3.4/contextlib.py\", line 66, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py\", line 3378, in get_controller\n",
      "    % type(default))\n",
      "AssertionError: Nesting violated for default stack of <class 'weakref'> objects\n"
     ]
    }
   ],
   "source": [
    "if not exists(join(root_path, model_name)):\n",
    "    mkdir(join(root_path, model_name))\n",
    "\n",
    "q_i2w, q_w2i = load_vocab('datasets/coco/train/questions.vocab')\n",
    "a_i2w, a_w2i = load_vocab('datasets/coco/train/answers.vocab')\n",
    "Nq = len(q_i2w)\n",
    "Na = len(a_i2w)\n",
    "\n",
    "max_q = train_set.max_q\n",
    "Nq = len(q_i2w)\n",
    "Na = len(a_i2w)\n",
    "\n",
    "\n",
    "dh = hyperparams[\"dh\"] #GRU hidden state dimension\n",
    "dq = hyperparams[\"dq\"] #Question embedding dimension\n",
    "da = hyperparams[\"da\"] #Answer embedding dimension\n",
    "di = hyperparams[\"di\"] #Image dimension\n",
    "batch_size = hyperparams[\"batch_size\"]\n",
    "keep_prob = hyperparams[\"keep_prob\"]\n",
    "cell = hyperparams[\"cell\"]\n",
    "\n",
    "print(\"Graph initialization\")\n",
    "tf.reset_default_graph()\n",
    "model = ImageQA(dh,dq,da,di,max_q,Nq,Na,cell,False)\n",
    "model_outputs = model.build_model(batch_size)\n",
    "\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.6)\n",
    "\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options, \n",
    "                                                   intra_op_parallelism_threads=4))\n",
    "\n",
    "writer = tf.train.SummaryWriter(join(root_path,model_name,'tf_log'), sess.graph)\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=100)\n",
    "\n",
    "\n",
    "# saver.restore(sess, '/home/hbenyounes/vqa/model2/model-8')\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "sess.run(init)\n",
    "\n",
    "\n",
    "sess.run(model.qemb_W.assign(emb))\n",
    "\n",
    "n_parameters = sum( [np.prod(v.get_shape(),dtype='int') for v in tf.trainable_variables()])\n",
    "hyperparams['n_parameters'] = n_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - 0/2460 : loss = nan - time = 0.000s\n",
      "Epoch 0 - 246/2460 : loss = 4.0994 - time = 50.390s\n",
      "Epoch 0 - 492/2460 : loss = 3.5805 - time = 100.483s\n",
      "Epoch 0 - 738/2460 : loss = 3.2929 - time = 150.895s\n",
      "Epoch 0 - 984/2460 : loss = 3.1152 - time = 201.302s\n",
      "Epoch 0 - 1230/2460 : loss = 2.9812 - time = 251.694s\n",
      "Epoch 0 - 1476/2460 : loss = 2.8801 - time = 302.139s\n",
      "Epoch 0 - 1722/2460 : loss = 2.7983 - time = 352.710s\n",
      "Epoch 0 - 1968/2460 : loss = 2.7308 - time = 403.260s\n",
      "Epoch 0 - 2214/2460 : loss = 2.6725 - time = 453.217s\n",
      "Epoch 1 - Test accuracy = 0.456\n",
      "Epoch 1 - 0/2460 : loss = nan - time = 0.000s\n",
      "Epoch 1 - 246/2460 : loss = 1.9718 - time = 50.220s\n",
      "Epoch 1 - 492/2460 : loss = 1.9913 - time = 101.068s\n",
      "Epoch 1 - 738/2460 : loss = 1.9889 - time = 152.059s\n",
      "Epoch 1 - 984/2460 : loss = 1.9819 - time = 202.988s\n",
      "Epoch 1 - 1230/2460 : loss = 1.9782 - time = 253.145s\n",
      "Epoch 1 - 1476/2460 : loss = 1.9729 - time = 303.799s\n",
      "Epoch 1 - 1722/2460 : loss = 1.9697 - time = 354.177s\n",
      "Epoch 1 - 1968/2460 : loss = 1.9609 - time = 404.770s\n",
      "Epoch 1 - 2214/2460 : loss = 1.9490 - time = 455.119s\n",
      "Epoch 2 - Test accuracy = 0.494\n",
      "Epoch 2 - 0/2460 : loss = nan - time = 0.000s\n"
     ]
    }
   ],
   "source": [
    "#Train\n",
    "break_all = False\n",
    "with tf.device('/gpu:0'):\n",
    "    n_epochs = 50\n",
    "    max_test_acc = -np.Inf\n",
    "    patience = 3\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = []\n",
    "        times = 0.\n",
    "        n_batches = train_set.N // batch_size\n",
    "        train_batches = train_set.batch_gen(batch_size)\n",
    "        for idx,batch in enumerate(train_batches):\n",
    "            tic = time()\n",
    "            if idx%(n_batches//10)==0:\n",
    "                print(\"Epoch %d - %d/%d : loss = %1.4f - time = %1.3fs\"%(epoch,idx,\n",
    "                                                                         n_batches,np.mean(epoch_loss),\n",
    "                                                                         times))\n",
    "            V,Q,mask,ans = create_feed_dict(batch,max_q,Na,batch_size)\n",
    "            _,l,l_s = sess.run([model_outputs['train_op'],\n",
    "                                model_outputs['loss'],\n",
    "                                model_outputs['loss_summary']], \n",
    "                               feed_dict={model_outputs['question']:Q,\n",
    "                                          model_outputs['mask']:mask,\n",
    "                                          model_outputs['answer']:ans,\n",
    "                                          model_outputs['image']:V,\n",
    "                                          model_outputs['keep_prob']:keep_prob})\n",
    "            if np.isnan(l):\n",
    "                break_all = True\n",
    "            epoch_loss.append(l)\n",
    "            writer.add_summary(l_s,idx+epoch*n_batches)\n",
    "            times += time() - tic\n",
    "            if break_all:\n",
    "                print(\"Loss is nan at iteration %d\" % (idx+n_batches*epoch))\n",
    "                break\n",
    "        if break_all:\n",
    "            break\n",
    "        with tf.device('/cpu:0'):\n",
    "            test_acc = test((1+epoch)*n_batches)\n",
    "            print(\"Epoch %d - Test accuracy = %1.3f\" % (epoch+1, test_acc))\n",
    "        if test_acc > max_test_acc:\n",
    "            patience += 3\n",
    "            saver.save(sess, join(root_path,model_name,'model'), global_step=epoch)\n",
    "        max_test_acc = max(test_acc, max_test_acc)\n",
    "        if epoch == patience:\n",
    "            print(\"EARLY STOPPING\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyperparams['max_test_acc'] = max_test_acc\n",
    "with open(join(root_path, model_name, 'hyperparams'),'w') as f:\n",
    "    for h in hyperparams:\n",
    "        f.write(\"%s = %s\\n\" % (h, str(hyperparams[h])))\n",
    "    f.write('\\n\\nMaximal test accuracy = %1.4f' % max_test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
