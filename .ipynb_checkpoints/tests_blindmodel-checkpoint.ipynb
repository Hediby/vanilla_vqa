{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import join\n",
    "from time import time\n",
    "import json\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import skimage\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "\n",
    "\n",
    "def load_image(path):\n",
    "    # load image\n",
    "    img = imread(path)\n",
    "    img = img / 255.0\n",
    "    assert (0 <= img).all() and (img <= 1.0).all()\n",
    "    #print \"Original Image Shape: \", img.shape\n",
    "    # we crop image from center\n",
    "    short_edge = min(img.shape[:2])\n",
    "    yy = int((img.shape[0] - short_edge) / 2)\n",
    "    xx = int((img.shape[1] - short_edge) / 2)\n",
    "    crop_img = img[yy : yy + short_edge, xx : xx + short_edge]\n",
    "    # resize to 224, 224\n",
    "    resized_img = resize(crop_img, (224, 224))\n",
    "    return resized_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image model\n",
    "\n",
    "This thing works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"vgg16.tfmodel\", mode='rb') as f:\n",
    "    fileContent = f.read()\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(fileContent)\n",
    "\n",
    "    images = tf.placeholder(\"float\", [None, 224, 224, 3])\n",
    "\n",
    "    tf.import_graph_def(graph_def, input_map={ \"images\": images })\n",
    "\n",
    "    graph = tf.get_default_graph()\n",
    "    out_tensor = graph.get_tensor_by_name(\"import/Relu_1:0\")\n",
    "\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "init = tf.initialize_all_variables()\n",
    "sess.run(init)\n",
    "\n",
    "batch = []\n",
    "path = '/home/hbenyounes/nshots/data_mostsim/unlabelized/'\n",
    "for i in listdir(path):\n",
    "    batch.append(load_image(join(path,i)))\n",
    "    if len(batch) >=16:\n",
    "        break\n",
    "batch = np.stack(batch)\n",
    "\n",
    "feed_dict = {images: batch}\n",
    "tic = time()\n",
    "with tf.device('/gpu:0'):\n",
    "    features2 = sess.run(out_tensor, feed_dict=feed_dict)\n",
    "toc = time() - tic\n",
    "print(features.shape, 'Time = %1.3fs'%toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def build_vocab(path):\n",
    "    saving_folder = \"/\".join(path.split('/')[:-1])\n",
    "    name = path.split('/')[-1].split('.')[0]\n",
    "    file = open(path,'r',encoding='latin1')\n",
    "    sentences = []\n",
    "    for l in file:\n",
    "        sentences.append(l.strip().split())\n",
    "    ct = Counter(x for a in sentences for x in a)\n",
    "    i2w = sorted(ct, key=ct.get, reverse=True)\n",
    "    i2w = ['<unk>','<s>', '</s>'] + i2w\n",
    "    w2i = dict((w,i) for i,w in enumerate(i2w))\n",
    "    vocab_file = open(join(saving_folder, name+'.vocab'), 'w',encoding='latin1')\n",
    "    for w in i2w:\n",
    "        vocab_file.write(w+'\\n')\n",
    "    vocab_file.close()\n",
    "    return 'done'\n",
    "\n",
    "def integerify(text_path, vocab_path, pad=False):\n",
    "    saving_folder = \"/\".join(text_path.split('/')[:-1])\n",
    "    name = text_path.split('/')[-1].split('.')[0]\n",
    "    w2i = {}\n",
    "    for i,l in enumerate(open(vocab_path,'r',encoding='latin1')):\n",
    "        l = l.strip()\n",
    "        w2i[l] = i\n",
    "    indexes_file = open(join(saving_folder, name+'.idxs'), 'w',encoding='latin1')\n",
    "    for l in open(text_path, 'r',encoding='latin1'):\n",
    "        l = l.strip().split() \n",
    "        if pad:\n",
    "            l = ['<s>'] + l + ['</s>']\n",
    "        idxs = []\n",
    "        for w in l:\n",
    "            if w in w2i:\n",
    "                idxs.append(str(w2i[w]))\n",
    "            else:\n",
    "                idxs.append(str(w2i['<unk>']))\n",
    "        indexes_file.write(' '.join(idxs) + '\\n')\n",
    "    return 'done'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_vocab('/home/hbenyounes/vqa/datasets/coco/train/questions.txt')\n",
    "build_vocab('/home/hbenyounes/vqa/datasets/coco/train/answers.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integerify('/home/hbenyounes/vqa/datasets/coco/train/questions.txt', \n",
    "           '/home/hbenyounes/vqa/datasets/coco/train/questions.vocab', pad=True)\n",
    "integerify('/home/hbenyounes/vqa/datasets/coco/train/answers.txt', \n",
    "           '/home/hbenyounes/vqa/datasets/coco/train/answers.vocab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integerify('/home/hbenyounes/vqa/datasets/coco/test/questions.txt', \n",
    "           '/home/hbenyounes/vqa/datasets/coco/train/questions.vocab', pad=True)\n",
    "integerify('/home/hbenyounes/vqa/datasets/coco/test/answers.txt', \n",
    "           '/home/hbenyounes/vqa/datasets/coco/train/answers.vocab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import join\n",
    "from time import time\n",
    "import json\n",
    "from collections import Counter\n",
    "from time import time\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from utils import load_dataset, load_vocab, get_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_vocab(vocab_path):\n",
    "    i2w = []\n",
    "    w2i = {}\n",
    "    for i,l in enumerate(open(vocab_path,'r',encoding='latin1')):\n",
    "        l = l.strip()\n",
    "        i2w.append(l)\n",
    "        w2i[l] = i\n",
    "    return i2w, w2i\n",
    "\n",
    "\n",
    "def load_dataset(idxs_path):\n",
    "    dataset = []\n",
    "    for l in open(idxs_path, 'r',encoding='latin1'):\n",
    "        dataset.append([int(i) for i in l.strip().split()])\n",
    "    return dataset\n",
    "\n",
    "def get_batch(begin,end,X,Y,\n",
    "              batch_size,max_q,Na):\n",
    "    Q = np.zeros((batch_size, max_q), 'int32')\n",
    "    mask = np.zeros((max_q,batch_size), 'int32')\n",
    "    for i,s in enumerate(X[begin:end]):\n",
    "        Q[i] = np.pad(s, (0,max_q-len(s)), 'constant')\n",
    "        mask[len(s)-1,i] = 1\n",
    "    ans = np.zeros((batch_size,Na),'int32')\n",
    "    for i,a in enumerate(Y[begin:end]):\n",
    "        ans[i,a] = 1\n",
    "    mask = mask[:,:,None]\n",
    "    return Q,mask,ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q_train = load_dataset('datasets/coco/train/questions.idxs')\n",
    "q_test = load_dataset('datasets/coco/test/questions.idxs')\n",
    "a_train = load_dataset('datasets/coco/train/answers.idxs')\n",
    "a_test = load_dataset('datasets/coco/test/answers.idxs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q_i2w, q_w2i = load_vocab('datasets/coco/train/questions.vocab')\n",
    "a_i2w, a_w2i = load_vocab('datasets/coco/train/answers.vocab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ImageQA(object):\n",
    "    def __init__(self, dh, dq, da, max_q, Nq, Na, infer=False):\n",
    "        self.dh = dh\n",
    "        self.dq = dq\n",
    "        self.da = da\n",
    "        self.max_q = max_q\n",
    "        self.Nq = Nq\n",
    "        self.Na = Na\n",
    "        self.infer = infer\n",
    "        \n",
    "        with tf.device('/cpu:0'):\n",
    "            self.qemb_W = tf.get_variable('qemb_w',\n",
    "                                          initializer=tf.random_uniform([self.Nq, self.dq], -0.1, 0.1))\n",
    "        self.aemb_W = tf.get_variable(name='aemb_w',\n",
    "                                      initializer=tf.random_uniform([self.dh, self.Na], -0.1, 0.1))\n",
    "        self.aemb_b = tf.get_variable(name='aemb_b',\n",
    "                                      initializer=tf.zeros([self.Na]))\n",
    "\n",
    "        self.gru = tf.nn.rnn_cell.GRUCell(self.dh)\n",
    "    def build_model(self,batch_size):\n",
    "        \n",
    "        p_question = tf.placeholder(tf.int32, \n",
    "                                    [None, self.max_q],\n",
    "                                    name=\"p_question\")\n",
    "        p_answer = tf.placeholder(tf.float32, \n",
    "                                  [None,self.Na],\n",
    "                                  name=\"p_answer\")\n",
    "        p_question_mask = tf.placeholder(tf.int32,\n",
    "                                         [self.max_q, None, None],\n",
    "                                         name=\"p_question_mask\")\n",
    "        \n",
    "        state = tf.zeros([batch_size, self.gru.state_size])\n",
    "        states = []\n",
    "        outputs = []\n",
    "        for j in range(self.max_q):\n",
    "            with tf.device('/cpu:0'):\n",
    "                question_emb = tf.nn.embedding_lookup(self.qemb_W, p_question[:,j])\n",
    "            if j>0:\n",
    "                tf.get_variable_scope().reuse_variables()\n",
    "            output,state = self.gru(question_emb, state)\n",
    "            states.append(state)\n",
    "            outputs.append(output)\n",
    "\n",
    "        output = tf.pack(outputs) # (max_words_q, batch_size, 4*dim_hidden)\n",
    "        output_final = tf.reduce_sum(tf.mul(output, tf.to_float(p_question_mask)),0) # (batch_size, 2*dim_hidden)\n",
    "\n",
    "        answer_logits = tf.nn.xw_plus_b(output_final,\n",
    "                                        self.aemb_W,\n",
    "                                        self.aemb_b) # (batch_size, num_answer)\n",
    "        answer_pred = tf.argmax(answer_logits,1)\n",
    "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(answer_logits, p_answer) # (batch_size, )\n",
    "        loss = tf.reduce_mean(cross_entropy)\n",
    "        train_op = tf.train.AdamOptimizer().minimize(loss)\n",
    "        loss_summary = tf.scalar_summary(\"loss\",loss,name=\"loss\")\n",
    "        output = {'train_op':train_op,\n",
    "                 'loss':loss,\n",
    "                 'question':p_question,\n",
    "                 'mask':p_question_mask,\n",
    "                 'answer':p_answer,\n",
    "                 'answer_pred':answer_pred,\n",
    "                 'loss_summary':loss_summary}\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(step,verbose=None):\n",
    "    N_test = len(q_test)\n",
    "    n_batches = N_test // batch_size\n",
    "    acc = []\n",
    "    for idx in range(n_batches):\n",
    "        if verbose:\n",
    "            if idx%20==0:\n",
    "                print(\"%d/%d - accuracy = %1.3f\"%(idx,n_batches, np.mean(acc)))\n",
    "        begin = idx*batch_size\n",
    "        end = min((idx+1)*batch_size, N_test)\n",
    "        Q, mask, A = get_batch(begin,end,q_test,a_test,batch_size,max_q,Na)\n",
    "        a_pred = sess.run(model_outputs['answer_pred'], \n",
    "                          feed_dict={model_outputs['question']:Q,\n",
    "                                     model_outputs['mask']:mask, \n",
    "                                     model_outputs['answer']:A})\n",
    "        equals = 1*np.equal(A.argmax(axis=1),a_pred)\n",
    "        equals = list(equals[:end-begin])\n",
    "        acc += equals\n",
    "    acc = tf.reduce_mean(tf.to_float(acc))\n",
    "    acc_s = tf.scalar_summary(\"acc_tf\",acc,name=\"acc_tf\")\n",
    "    acc,acc_s = sess.run([acc,acc_s])\n",
    "    writer.add_summary(acc_s,step)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_q = len(max(q_train, key=lambda x:len(x)))+1\n",
    "Nq = len(q_i2w)\n",
    "Na = len(a_i2w)\n",
    "\n",
    "dh = 50 #LSTM hidden state dimension\n",
    "dq = 75 #Question embedding dimension\n",
    "da = 50 #Answer embedding dimension\n",
    "batch_size = 64\n",
    "\n",
    "print(\"Graph initialization\")\n",
    "tf.reset_default_graph()\n",
    "model = ImageQA(dh,dq,da,max_q,Nq,Na,batch_size)\n",
    "model_outputs = model.build_model(batch_size)\n",
    "\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=100)\n",
    "writer = tf.train.SummaryWriter('/home/hbenyounes/vqa/tf_log', sess.graph)\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - 0/1231 : loss = nan - time = 0.000s\n",
      "Epoch 0 - 123/1231 : loss = 5.4648 - time = 0.000s\n",
      "Epoch 0 - 246/1231 : loss = 5.1740 - time = 0.000s\n",
      "Epoch 0 - 369/1231 : loss = 5.0072 - time = 0.000s\n",
      "Epoch 0 - 492/1231 : loss = 4.8797 - time = 0.000s\n",
      "Epoch 0 - 615/1231 : loss = 4.7827 - time = 0.000s\n",
      "Epoch 0 - 738/1231 : loss = 4.6957 - time = 0.000s\n",
      "Epoch 0 - 861/1231 : loss = 4.6221 - time = 0.000s\n",
      "Epoch 0 - 984/1231 : loss = 4.5568 - time = 0.000s\n",
      "Epoch 0 - 1107/1231 : loss = 4.4951 - time = 0.000s\n",
      "Epoch 0 - 1230/1231 : loss = 4.4421 - time = 0.000s\n",
      "Epoch 1 - 0/1231 : loss = nan - time = 0.000s\n",
      "Epoch 1 - 123/1231 : loss = 3.8649 - time = 0.000s\n",
      "Epoch 1 - 246/1231 : loss = 3.8479 - time = 0.000s\n",
      "Epoch 1 - 369/1231 : loss = 3.8141 - time = 0.000s\n",
      "Epoch 1 - 492/1231 : loss = 3.7917 - time = 0.000s\n",
      "Epoch 1 - 615/1231 : loss = 3.7608 - time = 0.000s\n",
      "Epoch 1 - 738/1231 : loss = 3.7370 - time = 0.000s\n",
      "Epoch 1 - 861/1231 : loss = 3.7123 - time = 0.000s\n",
      "Epoch 1 - 984/1231 : loss = 3.6906 - time = 0.000s\n",
      "Epoch 1 - 1107/1231 : loss = 3.6709 - time = 0.000s\n",
      "Epoch 1 - 1230/1231 : loss = 3.6493 - time = 0.000s\n",
      "Epoch 2 - 0/1231 : loss = nan - time = 0.000s\n",
      "Epoch 2 - 123/1231 : loss = 3.3182 - time = 0.000s\n",
      "Epoch 2 - 246/1231 : loss = 3.2958 - time = 0.000s\n",
      "Epoch 2 - 369/1231 : loss = 3.2794 - time = 0.000s\n",
      "Epoch 2 - 492/1231 : loss = 3.2613 - time = 0.000s\n",
      "Epoch 2 - 615/1231 : loss = 3.2450 - time = 0.000s\n",
      "Epoch 2 - 738/1231 : loss = 3.2335 - time = 0.000s\n",
      "Epoch 2 - 861/1231 : loss = 3.2191 - time = 0.000s\n",
      "Epoch 2 - 984/1231 : loss = 3.2039 - time = 0.000s\n",
      "Epoch 2 - 1107/1231 : loss = 3.1895 - time = 0.000s\n",
      "Epoch 2 - 1230/1231 : loss = 3.1805 - time = 0.000s\n",
      "Epoch 3 - 0/1231 : loss = nan - time = 0.000s\n",
      "Epoch 3 - 123/1231 : loss = 2.9298 - time = 0.000s\n",
      "Epoch 3 - 246/1231 : loss = 2.9084 - time = 0.000s\n",
      "Epoch 3 - 369/1231 : loss = 2.8942 - time = 0.000s\n",
      "Epoch 3 - 492/1231 : loss = 2.8965 - time = 0.000s\n",
      "Epoch 3 - 615/1231 : loss = 2.8863 - time = 0.000s\n",
      "Epoch 3 - 738/1231 : loss = 2.8792 - time = 0.000s\n",
      "Epoch 3 - 861/1231 : loss = 2.8646 - time = 0.000s\n",
      "Epoch 3 - 984/1231 : loss = 2.8561 - time = 0.000s\n",
      "Epoch 3 - 1107/1231 : loss = 2.8476 - time = 0.000s\n",
      "Epoch 3 - 1230/1231 : loss = 2.8422 - time = 0.000s\n",
      "Epoch 4 - 0/1231 : loss = nan - time = 0.000s\n",
      "Epoch 4 - 123/1231 : loss = 2.6459 - time = 0.000s\n",
      "Epoch 4 - 246/1231 : loss = 2.6233 - time = 0.000s\n",
      "Epoch 4 - 369/1231 : loss = 2.6306 - time = 0.000s\n",
      "Epoch 4 - 492/1231 : loss = 2.6277 - time = 0.000s\n",
      "Epoch 4 - 615/1231 : loss = 2.6242 - time = 0.000s\n",
      "Epoch 4 - 738/1231 : loss = 2.6219 - time = 0.000s\n",
      "Epoch 4 - 861/1231 : loss = 2.6238 - time = 0.000s\n",
      "Epoch 4 - 984/1231 : loss = 2.6213 - time = 0.000s\n",
      "Epoch 4 - 1107/1231 : loss = 2.6217 - time = 0.000s\n",
      "Epoch 4 - 1230/1231 : loss = 2.6139 - time = 0.000s\n",
      "Epoch 5 - 0/1231 : loss = nan - time = 0.000s\n",
      "Epoch 5 - 123/1231 : loss = 2.4433 - time = 0.000s\n",
      "Epoch 5 - 246/1231 : loss = 2.4472 - time = 0.000s\n",
      "Epoch 5 - 369/1231 : loss = 2.4538 - time = 0.000s\n",
      "Epoch 5 - 492/1231 : loss = 2.4516 - time = 0.000s\n",
      "Epoch 5 - 615/1231 : loss = 2.4491 - time = 0.000s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-5f6f0ad64cc1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m                                feed_dict={model_outputs['question']:Q,\n\u001b[0;32m     29\u001b[0m                                           \u001b[0mmodel_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mask'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m                                           model_outputs['answer']:A})\n\u001b[0m\u001b[0;32m     31\u001b[0m             \u001b[0mepoch_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml_s\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mn_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    370\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 372\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    373\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m       results = self._do_run(handle, target_list, unique_fetches,\n\u001b[1;32m--> 636\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    637\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m       \u001b[1;31m# The movers are no longer used. Delete them.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    706\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 708\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m    709\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    713\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 715\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    716\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m    695\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m    696\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 697\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Train\n",
    "q_train = np.array(q_train)\n",
    "a_train = np.array(a_train)\n",
    "with tf.device('/gpu:0'):\n",
    "    n_epochs = 50\n",
    "    N_train = len(q_train)\n",
    "    n_batches = N_train // batch_size + 1\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = []\n",
    "        times = 0.\n",
    "        indexes = np.arange(N_train)\n",
    "        np.random.shuffle(indexes)\n",
    "        q_train = q_train[indexes]\n",
    "        a_train = a_train[indexes]\n",
    "        for idx in range(n_batches):\n",
    "            tic = time()\n",
    "            if idx%(n_batches//10)==0:\n",
    "                print(\"Epoch %d - %d/%d : loss = %1.4f - time = %1.3fs\"%(epoch,idx,\n",
    "                                                                         n_batches,np.mean(epoch_loss),\n",
    "                                                                         times/((N_train//10)*batch_size)))\n",
    "                times = 0.\n",
    "            begin = idx*batch_size\n",
    "            end = min((idx+1)*batch_size, N_train)\n",
    "            Q, mask, A = get_batch(begin,end,q_train,a_train,batch_size,max_q,Na)\n",
    "            _,l,l_s = sess.run([model_outputs['train_op'],\n",
    "                                model_outputs['loss'],\n",
    "                                model_outputs['loss_summary']], \n",
    "                               feed_dict={model_outputs['question']:Q,\n",
    "                                          model_outputs['mask']:mask,\n",
    "                                          model_outputs['answer']:A})\n",
    "            epoch_loss.append(l)\n",
    "            writer.add_summary(l_s,idx+epoch*n_batches)\n",
    "            times += time() - tic\n",
    "        with tf.device('/cpu:0'):\n",
    "            test_acc = test((1+epoch)*n_batches)\n",
    "            print(\"Epoch %d - Test accuracy = %1.3f\" % (epoch+1, test_acc))\n",
    "        saver.save(sess, join('/home/hbenyounes/vqa/saved_models/','model'), global_step=epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
