{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 82783\n",
      "val 40504\n"
     ]
    }
   ],
   "source": [
    "from os.path import exists\n",
    "from os import mkdir\n",
    "from os.path import join\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import threading\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from scipy.misc import imread, imresize\n",
    "\n",
    "from utils import load_vocab\n",
    "from time import time\n",
    "import datetime\n",
    "\n",
    "\n",
    "image_paths = {}\n",
    "root_path = \"/srv/data/datasets/mscoco/images/\"\n",
    "\n",
    "for split in 'train val'.split():\n",
    "    image_ids_path = \"datasets/vqa/\"+split+\"/img_ids.txt\"\n",
    "    image_ids = set([int(x.strip()) for x in open(image_ids_path).readlines()])\n",
    "    print(split,len(image_ids))\n",
    "    for x in image_ids:\n",
    "        name = 'COCO_'+split+'2014_'+format(x, '012')+'.jpg'\n",
    "        path = join(root_path,split+\"2014\",name)\n",
    "        image_paths[x] = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_images(ps):\n",
    "    tic = time()\n",
    "    images = [imread(p,mode='RGB') for p in ps]\n",
    "    toc = time()\n",
    "    print(\"imread = %1.3fs\" % (toc-tic))\n",
    "    treated_images = []\n",
    "    sizes = []\n",
    "    for img in images:\n",
    "        sizes.append(img.shape[:2])\n",
    "        treated_img = imresize(img,(448,448),'nearest') / 255.0\n",
    "        treated_images.append(treated_img)\n",
    "    tic = time()\n",
    "    print(\"Resize / scaling = %1.3fs\" % (tic-toc))\n",
    "    return treated_images,sizes\n",
    "\n",
    "\n",
    "class Dataset(object):\n",
    "    def __init__(self,h5_path,image_paths,max_q=None,max_mc=None):\n",
    "        self.h5 = h5py.File(h5_path,mode='r')\n",
    "        self.image_ids = self.h5['image_ids'].value\n",
    "        self.questions = self.h5['questions'].value\n",
    "        self.multiple_choice = self.h5['multiple_choice'].value\n",
    "        self.answers = self.h5['answers'].value\n",
    "        self.bounding_boxes = dict((k,v) for (k,v) in zip(self.h5['img_list'].value, \n",
    "                                                          self.h5['bounding_boxes'].value))\n",
    "        self.N = len(self.image_ids)\n",
    "        if max_q:\n",
    "            if max_q<self.questions.shape[1]:\n",
    "                self.questions = self.questions[:,:max_q]\n",
    "            else:\n",
    "                self.questions = np.pad(self.questions,\n",
    "                                        ((0,0),(0,max_q-self.questions.shape[-1])),\n",
    "                                        'constant',constant_values=a_w2i['</s>'])\n",
    "        if max_mc:\n",
    "            if max_mc<self.multiple_choice.shape[-1]:\n",
    "                self.multiple_choice = self.multiple_choice[:,:,max_mc]\n",
    "            else:\n",
    "                self.multiple_choice = np.pad(self.multiple_choice,\n",
    "                                              ((0,0),(0,0),(0,max_mc-self.multiple_choice.shape[-1])),\n",
    "                                              'constant',constant_values=a_w2i['</s>'])\n",
    "        self.max_q = self.questions.shape[1]\n",
    "        self.indexes = np.arange(self.N)\n",
    "        self.image_paths = image_paths\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def batch_gen(self,batch_size=64,shuffle=True):\n",
    "        def load_image(p):\n",
    "            img = imread(p,mode='RGB')\n",
    "            size = img.shape[:2]\n",
    "            img = imresize(img,(448,448),'nearest') / 255.0\n",
    "            return img,size\n",
    "        \n",
    "        if shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "        n_batches = self.N // batch_size\n",
    "        tiled_batch = np.arange(batch_size)[:,None]\n",
    "        tiled_batch = np.tile(tiled_batch,(1,100))[:,:,None]\n",
    "        load_time = 0\n",
    "        for batch_id in range(n_batches):\n",
    "            begin = batch_id*batch_size\n",
    "            end = min((batch_id+1)*batch_size, self.N)\n",
    "            idxs = self.indexes[begin:end]\n",
    "            image_ids = self.image_ids[idxs]\n",
    "            images,sizes = [],[]\n",
    "            for i in image_ids:\n",
    "                p = self.image_paths[i]\n",
    "                img,size = load_image(p)\n",
    "                images.append(img)\n",
    "                sizes.append(size)\n",
    "            images = np.stack(images)\n",
    "            sizes = np.array(sizes)\n",
    "            questions = self.questions[idxs]\n",
    "            lengths = np.sum(np.not_equal(questions, \n",
    "                                          a_w2i['</s>']), \n",
    "                             axis=1)\n",
    "            question_mask = np.zeros((self.max_q,batch_size))\n",
    "            for i,q in enumerate(questions):\n",
    "                question_mask[lengths[i]-1,i] = 1\n",
    "            answers = self.answers[idxs]\n",
    "            multiple_choice = self.multiple_choice[idxs]\n",
    "            #lengths = np.sum(np.not_equal(multiple_choice,a_w2i['</s>']), axis=-1)\n",
    "            #multiple_choice = multiple_choice[:,:,:lengths.max()]\n",
    "            bbs = np.array([self.bounding_boxes[k] for k in image_ids])\n",
    "            bbs = np.concatenate((tiled_batch,bbs),axis=-1)\n",
    "            bounding_boxes = np.reshape(bbs, (bbs.shape[0]*bbs.shape[1],bbs.shape[2]))\n",
    "            yield (images,questions,question_mask,answers,multiple_choice,bounding_boxes,sizes)\n",
    "\n",
    "            \n",
    "q_i2w, q_w2i = load_vocab('datasets/vqa/train/questions.vocab')\n",
    "a_i2w, a_w2i = load_vocab('datasets/vqa/train/answers.vocab')\n",
    "            \n",
    "train_set = Dataset('datasets/vqa/train/dataset.h5',image_paths)\n",
    "max_mc = train_set.multiple_choice.shape[-1]\n",
    "max_q = train_set.max_q\n",
    "val_set = Dataset('datasets/vqa/val/dataset.h5',image_paths,max_q=max_q,max_mc=max_mc)\n",
    "Nq = len(q_i2w)\n",
    "Na = len(a_i2w)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
