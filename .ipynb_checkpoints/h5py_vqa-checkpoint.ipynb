{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from os.path import join\n",
    "\n",
    "def build_vocab(path,replacers):\n",
    "    saving_folder = \"/\".join(path.split('/')[:-1])\n",
    "    name = path.split('/')[-1].split('.')[0]\n",
    "    file = open(path,'r',encoding='latin1')\n",
    "    sentences = []\n",
    "    for l in file:\n",
    "        l = l.lower().strip()\n",
    "        for r1,r2 in replacers:\n",
    "            l = l.replace(r1,r2)\n",
    "        sentences.append(l.split())\n",
    "    file.close()\n",
    "    ct = Counter(x.strip() for a in sentences for x in a)\n",
    "    i2w = sorted(ct, key=ct.get, reverse=True)\n",
    "    i2w = ['<unk>','<s>', '</s>'] + i2w\n",
    "    w2i = dict((w,i) for i,w in enumerate(i2w))\n",
    "    vocab_file = open(join(saving_folder, name+'.vocab'), \n",
    "                      'w',encoding='latin1')\n",
    "    for w in i2w:\n",
    "        vocab_file.write(w+'\\n')\n",
    "    vocab_file.close()\n",
    "    return 'done'\n",
    "\n",
    "def integerify(text_path, vocab_path, pad=False, mc=False, replacers=[]):\n",
    "    saving_folder = \"/\".join(text_path.split('/')[:-1])\n",
    "    name = text_path.split('/')[-1].split('.')[0]\n",
    "    w2i = {}\n",
    "    for i,l in enumerate(open(vocab_path,\n",
    "                              'r',encoding='latin1')):\n",
    "        l = l.strip()\n",
    "        w2i[l] = i\n",
    "    indexes_file = open(join(saving_folder, name+'.idxs'), \n",
    "                        'w',encoding='latin1')\n",
    "    for l in open(text_path, 'r',encoding='latin1'):\n",
    "        l = l.lower().strip().replace('?','').split()\n",
    "        if pad:\n",
    "            l = ['<s>'] + l + ['</s>']\n",
    "        idxs = []\n",
    "        prev = ''\n",
    "        for w in l:\n",
    "            if mc and w=='|':\n",
    "                if (prev == w) or (prev == ''):\n",
    "                    print(\"Empty mc\")\n",
    "                    idxs.append(str(w2i['<unk>']))\n",
    "                idxs.append('|')\n",
    "            elif w in w2i:\n",
    "                idxs.append(str(w2i[w]))\n",
    "            else:\n",
    "                idxs.append(str(w2i['<unk>']))\n",
    "            if mc and i==len(l):\n",
    "                if len(w)==0:\n",
    "                    idxs.append(str(w2i['<unk>']))\n",
    "            prev = w\n",
    "        indexes_file.write(' '.join(idxs) + '\\n')\n",
    "    return 'done'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "questions_text = '/hhome/hbenyounes/vqa/datasets/vqa/train/questions.txt'\n",
    "mcs_text = '/hhome/hbenyounes/vqa/datasets/vqa/train/mcs.txt'\n",
    "\n",
    "\n",
    "build_vocab(questions_text,replacers=[('?',''),\n",
    "                                      ('\"',''),\n",
    "                                      (\"'\",' '),\n",
    "                                      ('.','')])\n",
    "build_vocab(mcs_text,replacers=[('|','')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from utils import load_vocab\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "split = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiple choice\n",
      "anwsers\n",
      "images\n",
      "questions\n",
      "bounding boxes\n",
      "save file\n",
      "multiple choice\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "zero\n",
      "anwsers\n",
      "Nothing\n",
      "images\n",
      "questions\n",
      "bounding boxes\n",
      "save file\n"
     ]
    }
   ],
   "source": [
    "for split in \"train val\".split():\n",
    "    a_i2w, a_w2i = load_vocab(\"/hhome/hbenyounes/vqa/datasets/vqa/train/answers.vocab\")\n",
    "    q_i2w,q_w2i = load_vocab(\"/hhome/hbenyounes/vqa/datasets/vqa/train/questions.vocab\")\n",
    "\n",
    "    mc_path = \"/hhome/hbenyounes/vqa/datasets/vqa/%s/mcs.idxs\"%split\n",
    "    a_path = \"/hhome/hbenyounes/vqa/datasets/vqa/%s/answers.idxs\"%split\n",
    "    i_path = \"/hhome/hbenyounes/vqa/datasets/vqa/%s/img_ids.txt\" % split\n",
    "    q_path = \"/hhome/hbenyounes/vqa/datasets/vqa/%s/questions.idxs\" % split\n",
    "    bb_path = \"/hhome/hbenyounes/vqa/datasets/vqa/%s/bounding_boxes.json\" % split\n",
    "    \n",
    "    print(\"multiple choice\")\n",
    "    mc_file = open(mc_path,'r')\n",
    "    multiple_choice = []\n",
    "    max_len = 0\n",
    "    for l in mc_file:\n",
    "        l = l.strip().split('|')\n",
    "        mcs = []\n",
    "        for mc in l:\n",
    "            mc = mc.split()\n",
    "            max_len = max(max_len,len(mc))\n",
    "            if len(mc) == 0:\n",
    "                print(\"zero\")\n",
    "            mcs.append(mc)\n",
    "        multiple_choice.append(mcs)\n",
    "    mc_file.close()\n",
    "    MC = np.zeros((len(multiple_choice),18,max_len),dtype='int') + a_w2i['</s>']\n",
    "    for i in range(len(multiple_choice)):\n",
    "        mcs = multiple_choice[i]\n",
    "        for j in range(18):\n",
    "            mc = mcs[j]\n",
    "            for k in range(len(mc)):\n",
    "                MC[i,j,k] = mc[k]\n",
    "    \n",
    "    print(\"anwsers\")\n",
    "    a_file = open(a_path,'r')\n",
    "    answers = []\n",
    "    for l in a_file:\n",
    "        l = l.strip()\n",
    "        l = [i for i in l.strip().split()]\n",
    "        answers.append(l)\n",
    "    a_file.close()\n",
    "\n",
    "    max_len = len(max(answers,key=lambda x:len(x)))\n",
    "    A = np.zeros((len(answers),18),dtype = 'int')\n",
    "    for i in range(len(answers)):\n",
    "        a = answers[i]\n",
    "        mcs = multiple_choice[i]\n",
    "        nothing = True\n",
    "        for j,x in enumerate(mcs):\n",
    "            A[i,j] = 1*(a==x)\n",
    "            if a==x:\n",
    "                nothing = False\n",
    "        if nothing:\n",
    "            print(\"Nothing\")\n",
    "            break\n",
    "\n",
    "    print(\"images\")\n",
    "    i_file = open(i_path,'r')\n",
    "    images = [int(i) for i in i_file.read().strip().split('\\n')]\n",
    "    i_file.close()\n",
    "\n",
    "    print('questions')\n",
    "    q_file = open(q_path,'r')\n",
    "    questions = []\n",
    "    lengths = []\n",
    "    for l in q_file:\n",
    "        l = l.strip()\n",
    "        l = [int(i) for i in l.strip().split()]\n",
    "        questions.append(l)\n",
    "        lengths.append(len(l))\n",
    "        \n",
    "    q_file.close()\n",
    "    max_len = max(lengths)\n",
    "    Q = np.zeros((len(questions),max_len),dtype = 'int') + q_w2i[\"</s>\"]\n",
    "    for i in range(len(questions)):\n",
    "        q = questions[i]\n",
    "        for j in range(lengths[i]):\n",
    "            Q[i,j] = q[j] \n",
    "    \n",
    "    print('bounding boxes')\n",
    "    bb_file = open(bb_path)\n",
    "    bb_dict = {}\n",
    "    for l in bb_file:\n",
    "        l = json.loads(l)\n",
    "        for k,v in l.items():\n",
    "            bb_dict[k] = v\n",
    "    bb_file.close()\n",
    "\n",
    "    bbs = list(bb_dict.values())\n",
    "    BBS = np.zeros((len(bbs),100, 4),dtype='int')\n",
    "    for i in range(len(bbs)):\n",
    "        bb = bbs[i]\n",
    "        bb = [bb[j % len(bb)] for j in range(100)]\n",
    "        BBS[i,:,:] = bb\n",
    "    \n",
    "    print(\"save file\")\n",
    "    f = h5py.File('/hhome/hbenyounes/vqa/datasets/vqa/%s/dataset.h5' % split)\n",
    "    f.create_dataset(\"answers\",dtype=\"uint8\",data=A)\n",
    "    f.create_dataset('image_ids',dtype=\"int\",data=images)\n",
    "    f.create_dataset(\"questions\",data=Q)\n",
    "    f.create_dataset(\"multiple_choice\",dtype=\"uint8\",data=MC)\n",
    "    f.create_dataset(\"img_list\",data=list(int(x) for x in bb_dict.keys()))\n",
    "    f.create_dataset(\"bounding_boxes\",data=BBS)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('not', 'allowed', 'horses,')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_i2w[184], a_i2w[5882], a_i2w[9247]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['6'],\n",
       " ['551'],\n",
       " ['2641'],\n",
       " ['7'],\n",
       " ['0'],\n",
       " ['9'],\n",
       " ['184', '5882'],\n",
       " ['5'],\n",
       " ['14'],\n",
       " ['9247', '169'],\n",
       " ['551', '979'],\n",
       " ['803', '1341'],\n",
       " ['13'],\n",
       " ['4'],\n",
       " ['8'],\n",
       " ['3'],\n",
       " ['225', '338', '2607'],\n",
       " ['10']]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
